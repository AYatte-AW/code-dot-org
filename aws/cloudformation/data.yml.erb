<%
require 'cdo/aws/data_pipeline'
require 'active_support/inflector'

tables_to_sync = %w(
  scripts
  followers
  stages
  script_levels
  workshops
  segments
  puzzle_ratings
  user_scripts
  channel_tokens
  levels
  user_proficiencies
  forms
  workshop_attendance
  hint_view_requests
  authored_hint_view_requests
  level_concept_difficulties
  survey_results
  sections
  users:id,deleted_at,created_at,updated_at,current_sign_in_at,last_sign_in_at,sign_in_count,admin,user_type,gender,birthday,locale,total_lines
)
-%>
---
AWSTemplateFormatVersion: 2010-09-09
Description: Data layer for Tableau including RedShift cluster configuration and scheduled Data Pipeline activities.
# Parameters can be provided via CDO.underscored_parameter, e.g. via locals.yml:
# redshift_password: abcdef
# Parameters are only required for initial stack creation, and reused if not provided on stack update.
Parameters:
  RedshiftPassword:
    Type: String
    NoEcho: true
  RDSPassword:
    Type: String
    NoEcho: true
  RedshiftUsername:
    Type: String
    Default: dev
  RDSUsername:
    Type: String
  RedshiftS3:
    Type: String
    Default: 's3://redshift-tableau'
  RedshiftDatabase:
    Type: String
    Default: dashboard
  RDSHostname:
    Type: String
  RDSPort:
    Type: Number
    Default: 3306
  DashboardDbName:
    Type: String
Resources:
  VPC: <%= lambda.call 'LookupStackOutputs', StackName: 'VPC', Nonce: 0 %>
  Tableau:
    Type: AWS::Redshift::Cluster
    Properties:
      AllowVersionUpgrade: true
      AutomatedSnapshotRetentionPeriod: 1
      ClusterParameterGroupName: default.redshift-1.0
      ClusterSubnetGroupName: {'Fn::GetAtt': [VPC, RedshiftSubnetGroup]}
      ClusterType: single-node
      ClusterVersion: 1.0
      DBName: {Ref: RedshiftDatabase}
      Encrypted: true
      KmsKeyId: alias/aws/redshift
      MasterUsername: {Ref: RedshiftUsername}
      MasterUserPassword: {Ref: RedshiftPassword}
      NodeType: dc1.large
      PubliclyAccessible: true
      VpcSecurityGroupIds: ['Fn::GetAtt': [VPC, RedshiftSecurityGroup]]
<%
tables_to_sync.each do |table_select|
  table, select_query = table_select.split(':')
%>
  RDSCopy<%=table.camelize%>: <%= AWS::DataPipeline.to_cfn(
    "rds-to-redshift-#{table}#{'-whitelisted-columns' if select_query}",
    "Copy #{table} from RDS to Redshift",
    File.read(aws_dir('cloudformation', 'pipeline.json.erb')),
    table_name: table,
    select_query: select_query || '*',
    az: azs.first
  )%>
<% end %>
Outputs:
  Redshift:
    Description: Tableau endpoint
    Value: {Ref: Tableau}
